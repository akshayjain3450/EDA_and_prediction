{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# EDA, Data cleaning, visualization and House price Prediction\n",
    "## You will see prediction and performance with almost all models using **LazyPredict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lightgbm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0debfd4f29ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLGBMRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lightgbm'"
     ]
    }
   ],
   "source": [
    "# Importing the dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "pd.pandas.set_option('display.max_columns',None)\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import sklearn.metrics as metrics\n",
    "import math\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv('/home/dheeraj/my_projects/my_project_env/practice/EDA_and_prediction/EDA_FE_FS_House_Price_Prediction/train.csv')   # importing the training data file\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()          # Print the top 5 values of the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=pd.read_csv('/home/dheeraj/my_projects/my_project_env/practice/EDA_and_prediction/EDA_FE_FS_House_Price_Prediction/test.csv')      # importing the test data file\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Let's do some EDA on training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_with_na = [features for features in train_df.columns if train_df[features].isnull().sum() >1]\n",
    "print(\"Total number of features having some nan values is: \", len(column_with_na))\n",
    "column_with_na"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the percentage of Nan values in the columns we got in above shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for features in column_with_na:\n",
    "    print(\"Column\", features, \"have\", np.round(train_df[features].isnull().mean(), 4)*100, \"% NaN value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's find the reationship b/w columns with nan values and 'Sale price' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for features in column_with_na:\n",
    "    data = train_df.copy() \n",
    "    data[features] = np.where(data[features].isnull(), 1, 0)\n",
    "    col = [\"red\", \"green\"]\n",
    "    data.groupby(features)['SalePrice'].median().plot.bar(color = col)\n",
    "    plt.title(features)\n",
    "    plt.show()\n",
    "    \n",
    "## we can see in the output of this shell that, there's no such specific patterns we're getting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the columns with Numerical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_with_numerical_values = [features for features in train_df.columns if train_df[features].dtypes != 'O']\n",
    "print(\"Total number of features with numerical values is: \", len(column_with_numerical_values))\n",
    "# column_with_numerical_values\n",
    "train_df[column_with_numerical_values].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of unique values in Columns with numerical Feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in column_with_numerical_values:\n",
    "    data = train_df.copy()\n",
    "    print(feature, len(data[feature].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns with discrete values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_discrete_values = [feature for feature in column_with_numerical_values if len(train_df[feature].unique()) <25]\n",
    "print(\"Total number of numerical features with discrete values is: \", len(column_discrete_values))\n",
    "data[column_discrete_values].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationship between columns(we got from above shell) having discrete values with 'SalePrice'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in column_discrete_values:\n",
    "    data = train_df.copy()    \n",
    "    data.groupby(feature)['SalePrice'].median().plot.bar()\n",
    "    plt.title(feature)\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(\"Sales Price\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns with continuous values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_continuous_values = [feature for feature in column_with_numerical_values if len(train_df[feature].unique()) >=25]\n",
    "print(\"Total number of numerical features with discrete values is: \", len(column_continuous_values))\n",
    "data[column_continuous_values].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationship b/w columns with continuous values with 'SalePrice' (by plotting Histograms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in column_continuous_values:\n",
    "    if feature != 'Id':  \n",
    "        data[feature].hist(bins=25)\n",
    "        plt.title(feature)\n",
    "        plt.xlabel(feature)\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Since we didn't get any good insights from above relationship plots, so we'll make scatter plot by taking log of 'SalePrice' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in column_continuous_values:\n",
    "    if feature != 'Id':  \n",
    "        data = train_df.copy()\n",
    "        if 0 in data[feature].unique():\n",
    "            pass\n",
    "        else:\n",
    "            data[feature] = np.log(data[feature])\n",
    "            data['SalePrice'] = np.log(data['SalePrice'])\n",
    "            plt.scatter(data[feature], data['SalePrice'])\n",
    "            plt.title(feature)\n",
    "            plt.xlabel(feature)\n",
    "            plt.ylabel(\"Count\") \n",
    "            plt.show()\n",
    "## We can see in the output of this shell that most of the plots showing linear corelation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we'll check for some outliers in the features having continuous values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in column_continuous_values:\n",
    "    if feature != 'Id':  \n",
    "        data = train_df.copy()\n",
    "        if 0 in data[feature].unique():\n",
    "            pass\n",
    "        else:\n",
    "            data[feature] = np.log(data[feature])\n",
    "#             data['SalePrice'] = np.log(data['SalePrice'])\n",
    "            data.boxplot(column = feature)\n",
    "            plt.title(feature)\n",
    "#             plt.xlabel(feature)\n",
    "            plt.ylabel(feature) \n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ## Number of unique values in Columns with Categorical Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_with_categorical_values = [features for features in train_df.columns if train_df[features].dtypes == 'O']\n",
    "\n",
    "\n",
    "print(\"Total number of features with numerical values is: \", len(column_with_categorical_values))\n",
    "# column_with_categorical_values\n",
    "train_df[column_with_categorical_values].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in column_with_categorical_values:\n",
    "    data = train_df.copy()\n",
    "    print(feature, len(data[feature].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the columns with categorical data with 'SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in column_with_categorical_values:\n",
    "    data = train_df.copy()    \n",
    "    data.groupby(feature)['SalePrice'].median().plot.bar()\n",
    "    plt.title(feature)\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(\"Sales Price\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_with_year = [feature for feature in column_with_numerical_values if 'Yr' in feature or 'Year' in feature]\n",
    "print(\"Total number of features with date entries is: \", len(column_with_year))\n",
    "train_df[column_with_year]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realationship b/w 'YrSold' column with 'SalePrice' (taking groupby wrt. saleprice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.groupby('YrSold')['SalePrice'].median().plot()\n",
    "plt.title('Median Sale Price vs Sold Year')\n",
    "plt.ylabel('Sale price')\n",
    "plt.xlabel('Year Sold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationship b/w different year column (subtracted with sold year) with 'SalePrice'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in column_with_year:\n",
    "    if feature != 'YrSold':\n",
    "        data = train_df.copy()\n",
    "        data[feature] = data['YrSold'] - data[feature]\n",
    "        plt.scatter(data[feature], data['SalePrice'])\n",
    "        plt.title(\"Year features vs Sales price\")\n",
    "        plt.xlabel(feature)\n",
    "        plt.ylabel(\"Sale Price\")\n",
    "        plt.show()\n",
    "# We can see if the year gap is more the price is less"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature engineering\n",
    "\n",
    "### We will do feature engineering after combining both test and training dataset, to avoid repetition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['SalePrice'] = 0\n",
    "print(\"The shape of given test data is: \", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## we'll concatenate both table\n",
    "full_df_feature_eng = pd.concat([train_df, test_df], axis=0,sort=False)\n",
    "print(\"The shape of dataset after combining both test and train dataset is: \",full_df_feature_eng.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_feature_eng.tail()   # Print the tail end of the combined datsset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical columns with some NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_nan_in_categorical =[features for features in full_df_feature_eng.columns if full_df_feature_eng[features].isnull().sum()>1 and full_df_feature_eng[features].dtypes=='O']\n",
    "print(\"Total number of categorical features having some nan values is: \", len(columns_nan_in_categorical), \"\\n\")\n",
    "for features in columns_nan_in_categorical:\n",
    "    print(\"Column\", features, \"have\", np.round(full_df_feature_eng[features].isnull().mean(), 4)*100, \"% NaN value\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_feature_eng[columns_nan_in_categorical].head()  # Printing all the categorical columns with Nan values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill the all the Nan with 'Missing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for features in columns_nan_in_categorical:\n",
    "    full_df_feature_eng[features] = full_df_feature_eng[features].fillna('Missing')\n",
    "\n",
    "full_df_feature_eng[columns_nan_in_categorical].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical columns with some NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_nan_in_numerical =[features for features in full_df_feature_eng.columns if full_df_feature_eng[features].isnull().sum()>1 and full_df_feature_eng[features].dtypes!='O']\n",
    "print(\"Total number of numerical features having some nan values is: \", len(columns_nan_in_numerical), \"\\n\")\n",
    "\n",
    "for features in columns_nan_in_numerical:\n",
    "    print(\"Column\", features, \"have\", np.round(full_df_feature_eng[features].isnull().mean(), 4)*100, \"% NaN value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_feature_eng[columns_nan_in_numerical].head()   # Printing all the numerical columns with Nan values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace all the Nan values of numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for features in columns_nan_in_numerical:\n",
    "    full_df_feature_eng[features+'Nan'] = np.where(full_df_feature_eng[features].isnull(), 1, 0) \n",
    "    full_df_feature_eng[features].fillna(full_df_feature_eng[features].median(), inplace = True)\n",
    "    \n",
    "for features in columns_nan_in_numerical:\n",
    "    print(\"Column\", features, \"have\", np.round(full_df_feature_eng[features].isnull().mean(), 4)*100, \"% NaN value\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_feature_eng.head()      ## we'll print the dataframe after adding 5 new columns that had nan value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now apply log operation on some columns with big values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features=['LotFrontage', 'LotArea', '1stFlrSF', 'GrLivArea', 'SalePrice']\n",
    "\n",
    "for feature in num_features:\n",
    "    full_df_feature_eng[feature]=np.log(full_df_feature_eng[feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we'll handle categorical variable\n",
    "### Print all the features with categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_column_in_full_data = [feature for feature in full_df_feature_eng.columns if full_df_feature_eng[feature].dtype=='O']\n",
    "print(categorical_column_in_full_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We'll encode the the categorical variables with ranks generated by taking groupby and mean, as you can see below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for features in categorical_column_in_full_data:\n",
    "    labels_encode=full_df_feature_eng.groupby([features])['SalePrice'].mean().sort_values().index\n",
    "    labels_encode={k:i for i,k in enumerate(labels_encode,0)}\n",
    "    full_df_feature_eng[features]=full_df_feature_eng[features].map(labels_encode)\n",
    "full_df_feature_eng.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_feature_eng.info()   ## Print all the columns, we can see there's no null values now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a list of independent variable (excluding 'SalePrice' and 'Id', which is dependent variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "independent_feature = [features for features in full_df_feature_eng.columns if features not in ['Id', 'SalePrice']]\n",
    "print(independent_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we'll do some feature scaling to get good results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(full_df_feature_eng[independent_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.transform(full_df_feature_eng[independent_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaled_independent =  pd.DataFrame(scaler.transform(full_df_feature_eng[independent_feature]), columns=independent_feature)\n",
    "data_scaled_independent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, after doing feature scaling of independent variable, we'll concatenate it with 'SalePrice' & 'Id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_data = pd.concat([full_df_feature_eng[['Id', 'SalePrice']].reset_index(drop = True), pd.DataFrame(scaler.transform(full_df_feature_eng[independent_feature]), columns=independent_feature)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now after doing Feature engn. we'll separate both train and test datasets, for further operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "given_train = concat_data[0:1460]\n",
    "given_test = concat_data[1460:2919]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make two dataframe, one for dependent and other for independent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  We'll \n",
    "X = given_train.drop(['SalePrice',\n",
    "                              'Id'], axis = 1) \n",
    "target = given_train['SalePrice']\n",
    "print(\"Dependent Variables\")\n",
    "display(X.head())\n",
    "print(\"Independent Variable\")\n",
    "display(target.to_frame().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We'll firsts predict using LazyPredict to see the performance of almost all the regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install lazypredict             # install Lazypredict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We'll firstly split our given training dataset into train & test set for our model, and analyse the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "from lazypredict.Supervised import LazyRegressor\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, target,test_size=.3,random_state =23)\n",
    "regr=LazyRegressor(verbose=0,predictions=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time_2=time.time()\n",
    "models_r,predictions_r=regr.fit(X_train, X_test, Y_train, Y_test)\n",
    "end_time_2=time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can see models with their performance, HuberRegressor giving the best result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_r    ## Shows performance table by all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_r  ## Print the predicted values from all the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we'll predict from the required model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply same data used in Lazy Predict i.e, only traing data (splitting it into train and test set) in XGB and LGBM regressor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_train = given_test.drop(['SalePrice','Id'], axis = 1)       ## Drop the two columns that we added while feature engineering in concatenated file\n",
    "submission_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First apply the XGB model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb =XGBRegressor( booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=0.6, gamma=0,\n",
    "             importance_type='gain', learning_rate=0.01, max_delta_step=0,\n",
    "             max_depth=4, min_child_weight=1.5, n_estimators=2400,\n",
    "             n_jobs=1, nthread=None, objective='reg:linear',\n",
    "             reg_alpha=0.6, reg_lambda=0.6, scale_pos_weight=1, \n",
    "             silent=None, subsample=0.8, verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train, X_Test, Y_Train, Y_Test = train_test_split(X, target,test_size=.15,random_state =123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting\n",
    "xgb.fit(X_Train, Y_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predict_sample = xgb.predict(X_Test)\n",
    "print('RMSE = ' + str(math.sqrt(metrics.mean_squared_error(Y_Test, xgb_predict_sample))))          ## print the error "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the LGBM regressor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = LGBMRegressor(objective='regression', \n",
    "                                       num_leaves=3,\n",
    "                                       learning_rate=0.006, \n",
    "                                       n_estimators=12000, \n",
    "                                       max_bin=200, \n",
    "                                       bagging_fraction=0.75,\n",
    "                                       bagging_freq=5, \n",
    "                                       bagging_seed=7,\n",
    "                                       feature_fraction=0.4,   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm.fit(X_Train, Y_Train,eval_metric='rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_predict_sample = lgbm.predict(X_Test)\n",
    "print('RMSE = ' + str(math.sqrt(metrics.mean_squared_error(Y_Test, lgbm_predict_sample))))       ## Print the error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use whole original given training dataset file for model fitting & further apply the model on testing file to get the required prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we'll apply both model and will take the average og predicted values from both the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.fit(X, target)   ## fiting xgb model\n",
    "lgbm.fit(X, target,eval_metric='rmse')    ## fitting lgbm model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we'll calculate the predicted values, and take the average of both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_predict_on_provided_test_data = lgbm.predict(submission_train)     \n",
    "xgb_predict_on_provided_test_data = xgb.predict(submission_train)\n",
    "req_prediction = ( lgbm_predict_on_provided_test_data*0.5 + xgb_predict_on_provided_test_data * 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Since we have taken log of the 'SalePrice column while feature engineering, so now we'll take antilog of it to get the final predicted prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "antilog_of_prediction = np.exp(req_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we'll make a dataframe of predicted values with the corresponding 'Id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prediction = pd.DataFrame({\n",
    "        \"Id\": test_df[\"Id\"],\n",
    "        \"SalePrice\": antilog_of_prediction\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can check the shape of final dataframe, its of two columns, predicted prices and respective Ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of final dataframe is: \", final_prediction.shape)\n",
    "final_prediction.head()                                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally we'll submit the predicted results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prediction.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
